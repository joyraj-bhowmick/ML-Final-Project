{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9867fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluation metrics R-precision and Normalized discouunted cumulative gain (NDCG)\n",
    "as defined by the Spotify Million Playlist Dataset Competition:\n",
    "https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge\n",
    "\n",
    "Code and methods follow those described by Vagliano et al:\n",
    "https://pure.mpg.de/rest/items/item_3367572_1/component/file_3367573/content\n",
    "\"\"\"\n",
    "\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "\n",
    "\n",
    "def r_precision(target, prediction, max_n_prediction=500):\n",
    "    '''R-precision evaluation metric'''\n",
    "    pred = prediction[:max_n_prediction]\n",
    "    targetset = set(target)\n",
    "    \n",
    "    denominator = len(targetset)\n",
    "    numerator = float(len(set(pred[:denominator]).intersection(targetset)))\n",
    "    \n",
    "    r_prec_val = numerator/denominator\n",
    "    return r_prec_val\n",
    "\n",
    "def dcg(relevant, retrieved, k, *args, **kwargs):\n",
    "    '''Discounted Cumulative Gain'''\n",
    "    list1 = retrieved[:k]\n",
    "    retrieved = list(OrderedDict.fromkeys(list1))\n",
    "    relevant = list(OrderedDict.fromkeys(relevant))\n",
    "    \n",
    "    if (len(relevant) == 0 or len(retrieved) == 0):\n",
    "        return 0.0\n",
    "    \n",
    "    else:\n",
    "        rel_i = [float(el in relevant) for el in retrieved]\n",
    "        rel_i_len = len(rel_i)+1\n",
    "        \n",
    "        i_variable = 1 + np.arange(1, rel_i_len)\n",
    "        denominator = np.log2(i_variable)\n",
    "        \n",
    "        dcg_val = np.sum(rel_i/denominator)\n",
    "        return dcg_val\n",
    "    \n",
    "def idcg(relevant, retrieved, k, *args, **kwargs):\n",
    "    '''Ideal Discounted Cumulative Gain'''\n",
    "    k_min = min(k, len(relevant))\n",
    "    idcg_val = dcg(relevant, relevant, k_min)\n",
    "    return idcg_val\n",
    "\n",
    "def ndcg(relevant, retrieved, k, *args, **kwargs):\n",
    "    '''Normalized Discounted Cumulative Gain'''\n",
    "    dcg_val = dcg(relevant, retrieved, k)\n",
    "    idcg_val = idcg(relevant, retrieved, k)\n",
    "    \n",
    "    if idcg_val == 0:\n",
    "        raise ValueError(\"relevent is empty, divide by 0 error\")\n",
    "    \n",
    "    ndcg_val = dcg_val / idcg_val\n",
    "    return ndcg_val\n",
    "\n",
    "\n",
    "Metrics = namedtuple('Metrics', ['r_precision', 'ndcg'])\n",
    "\n",
    "def get_all_metrics(target, prediction, k):\n",
    "    '''Return tuple of each evaluation metric'''\n",
    "    r_prec_val = r_precision(target, prediction, k)\n",
    "    ndcg_val = ndcg(target, prediction, k)\n",
    "    \n",
    "    Metrics_val = Metrics(r_prec_val, ndcg_val)\n",
    "    return Metrics_val\n",
    "\n",
    "Metrics_Summary = namedtuple('MetricsSummary', ['mean_r_precision','mean_ndcg','coverage'])\n",
    "\n",
    "def aggregate_metrics(ground_truth, sub, k, candidates):\n",
    "    '''Return tuple of the means of each evaluation metric'''\n",
    "    r_precision_vals = []\n",
    "    ndcg_vals = []\n",
    "    miss_vals = 0\n",
    "    counts = 0\n",
    "    \n",
    "    for i in candidates:\n",
    "        counts += 1\n",
    "        if i not in sub:\n",
    "            miss_vals += 1\n",
    "            m = Metrics(0, 0, 0) \n",
    "        else:\n",
    "            m = get_all_metrics(ground_truth[i], sub[i], k)\n",
    "        r_precision_vals.append(m.r_precision)\n",
    "        ndcg_vals.append(m.ndcg)\n",
    "\n",
    "    coverage_val = 1 - miss_vals / float(counts)\n",
    "    r_prec_mean = stats.describe(r_precision).mean\n",
    "    ndcg_mean = stats.describe(ndcg).mean\n",
    "    Metrics_Summary_val = Metrics_Summary(r_prec_mean,ndcg_mean,coverage_val)\n",
    "    return Metrics_Summary_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f49edc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.load(\"datasets/testlabels.npy\")\n",
    "pred_labels = genfromtxt(\"densenet_predictions.csv\", delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73a83449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "718f8a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(my_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bb7ee01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018867924528301886"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_precision(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00b70165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcg(true_labels, pred_labels, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9215cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = get_all_metrics(true_labels, pred_labels, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0576c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metrics(r_precision=0.018867924528301886, ndcg=0.07450728404752761)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a6a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
